{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSpy Ollama Custom Examples with Custom Ollama based Retriever for ChromaDB \n",
    "\n",
    "## Anchknowledgements and premise of writng this code\n",
    "\n",
    "The methods and ways mentionned in most of the `DSPy` examples that uses `ChromadbRM` ,`ColBERTv2`, `MilvusRM`, `QdrantRM`, `WeaviateRM`  etc fails \n",
    "to consider these points mentionned below:\n",
    "\n",
    "1. Everybody is Not a seasoned progrmmaer who can easily spin-up local databases, web servers on a whim!\n",
    "2. LLM != `GPT-4` or `GPT-3.5` or `Grok` or `Claude` or any other bigshot expensive money burning exernal api keys that makes a big hole in a `Dev`'s Pocket and Morale\n",
    "3. I Whole heartedly respect and love all those investors and Scientists who made it possible to develop and use all these Greate LLms, But Being a  Biologist to turned himself from coding Dna to Coding LLMs, I believe  \n",
    "> **Life** (and a pair of `Kanjoose Bengali Engineers` üòâ ) always finds a way! (To get away with doing things easy and for free üòù)\n",
    "4. Sorry for diverting into the cavernous side alleys of insomniac thoughts.\n",
    "5. And another issue is that everyone is not a guy who uses pthon with *OOPs*, and this can be a big OOps!! for a lot of newcommers =`nc`\n",
    "\n",
    "\n",
    "## What did I do\n",
    "\n",
    "Well well, being a subset of `nc` myself (with a history of making complex programms in [Blender's](https://www.blender.org/)  Geometry node) and having blessed with Guides, friends and Youtubers  Like [Arnav Singhvi](https://www.linkedin.com/in/arnav-singhvi-1323a7189/) & [Herumb Shandilya](https://www.linkedin.com/in/herumb-shandilya/) from [`DSPy`](https://dspy-docs.vercel.app/)\n",
    "[Connor Shorten](https://www.linkedin.com/in/connor-shorten-34923a178/) from [`Weaviate`](https://www.linkedin.com/company/weaviate-io/) and [Tamoghna Das](https://www.linkedin.com/in/tamoghnadas12/), My College senior who brought me into this world of LLms in November 2022. And The last but Not the least [`Perplexity`](https://www.perplexity.ai/) for enabling millions like me who are a subset of `nc` to code without fear of syntaxes. \n",
    "\n",
    "1. Studied the Ollama Library in python that is given by [ollama](https://ollama.com/) and make an embedder:retiever  function pair\n",
    "2. made a local server of Ollama and Chromadb run from a given directory from urls `http://localhost:11434/` and `http://localhost:8000/` respectively.\n",
    "3. Used NLTK's `Sent_tokenize` for chunking the text into sentences that will be fed to the ChromaDB \n",
    "4. Made a Ollama based LLM run in DSPy\n",
    "5. Created the default `GenerateAnswer` and `GenerateSearchQuery` `Signature`s for Rag (Never used the `GenerateSearchQuery` for being a noob myself üòù)\n",
    "6. Created a `markdown` file that has the data I am doing `RAG` on (in a later example I will show you how to do rag on web search data)\n",
    "\n",
    "\n",
    "## So let's jump into the project!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"dspy-ai[chromadb]\"\n",
    "! pip install pandas \n",
    "! pip install nltk\n",
    "! pip install requests\n",
    "! pip install ollama\n",
    "\n",
    "# if you are following this example in 2024 September then there is a numpy based error in chromadb \n",
    "# that root's from numpy using npfloat64 instead of npfloat_ in numpy 2.x.x and higher versions so be prepared to go into the site pakcages of chromadb \n",
    "# in .venv/lib/python3.11/site-packages/chromadb/api/types.py in line no. 102 and fix it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### start the server and go to `DSpy_Ollama_Chroma_Rag.ipynb` keep this notebook running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "                \u001b[38;5;069m(((((((((    \u001b[38;5;203m(((((\u001b[38;5;220m####\n",
      "             \u001b[38;5;069m(((((((((((((\u001b[38;5;203m(((((((((\u001b[38;5;220m#########\n",
      "           \u001b[38;5;069m(((((((((((((\u001b[38;5;203m(((((((((((\u001b[38;5;220m###########\n",
      "         \u001b[38;5;069m((((((((((((((\u001b[38;5;203m((((((((((((\u001b[38;5;220m############\n",
      "        \u001b[38;5;069m(((((((((((((\u001b[38;5;203m((((((((((((((\u001b[38;5;220m#############\n",
      "        \u001b[38;5;069m(((((((((((((\u001b[38;5;203m((((((((((((((\u001b[38;5;220m#############\n",
      "         \u001b[38;5;069m((((((((((((\u001b[38;5;203m(((((((((((((\u001b[38;5;220m##############\n",
      "         \u001b[38;5;069m((((((((((((\u001b[38;5;203m((((((((((((\u001b[38;5;220m##############\n",
      "           \u001b[38;5;069m((((((((((\u001b[38;5;203m(((((((((((\u001b[38;5;220m#############\n",
      "             \u001b[38;5;069m((((((((\u001b[38;5;203m((((((((\u001b[38;5;220m##############\n",
      "                \u001b[38;5;069m(((((\u001b[38;5;203m((((    \u001b[38;5;220m#########\u001b[0m\n",
      "\n",
      "    \n",
      "\u001b[1m\n",
      "Running Chroma\n",
      "\u001b[0m\n",
      "\u001b[1mSaving data to\u001b[0m: \u001b[32m./ChomaM/my_chroma_db1\u001b[0m\n",
      "\u001b[1mConnect to chroma at\u001b[0m: \u001b[32mhttp://localhost:8000\u001b[0m\n",
      "\u001b[1mGetting started guide\u001b[0m: https://docs.trychroma.com/getting-started\n",
      "\n",
      "\n",
      "\u001b[33mWARNING\u001b[0m:  [02-09-2024 18:11:01] chroma_server_nofile is set to 65535, but this is less than current soft limit of 1048576. chroma_server_nofile will not be set.\n",
      "\u001b[32mINFO\u001b[0m:     [02-09-2024 18:11:01] Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "\u001b[36mDEBUG\u001b[0m:    [02-09-2024 18:11:01] Starting component System\n",
      "\u001b[36mDEBUG\u001b[0m:    [02-09-2024 18:11:01] Starting component OpenTelemetryClient\n",
      "\u001b[36mDEBUG\u001b[0m:    [02-09-2024 18:11:01] Starting component SimpleAssignmentPolicy\n",
      "\u001b[36mDEBUG\u001b[0m:    [02-09-2024 18:11:01] Starting component SqliteDB\n",
      "\u001b[36mDEBUG\u001b[0m:    [02-09-2024 18:11:01] Starting component QuotaEnforcer\n",
      "\u001b[36mDEBUG\u001b[0m:    [02-09-2024 18:11:01] Starting component Posthog\n",
      "\u001b[36mDEBUG\u001b[0m:    [02-09-2024 18:11:01] Starting component LocalSegmentManager\n",
      "\u001b[36mDEBUG\u001b[0m:    [02-09-2024 18:11:01] Starting component SegmentAPI\n",
      "\u001b[32mINFO\u001b[0m:     [02-09-2024 18:11:01] Started server process [\u001b[36m7810\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     [02-09-2024 18:11:01] Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     [02-09-2024 18:11:01] Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     [02-09-2024 18:11:01] Uvicorn running on \u001b[1mhttp://localhost:8000\u001b[0m (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!chroma run --host localhost --port 8000 --path ./ChomaM/my_chroma_db1  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
